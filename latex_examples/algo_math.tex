%\documentclass[a4paper, 10pt]{article}
\documentclass[a4paper, 10pt,twocolumn]{article}

\usepackage{amsmath}
%\usepackage{algorithm2e}
\usepackage{algorithm}
\usepackage{algpseudocode}


\title{Comparison Based Sorting Algorithms}
\author{Bhavishya}
\date{}
\begin{document}
\maketitle
\begin{abstract}
This document presents a brief discussion on sort-
    ing algorithms. Algorithms for \texttt{Quicksort} is pro-
vided in this document and its working is explained.
Further, a proof of lower bounds on sorting is pre-
sented in this document. Most of the content pre-
sented here is created by referring and reproducing
contents from one of the widely followed book on
Algorithms by Cormen et al. [1]. \textbf{We do not claim
originality of this work.} This document is pre-
pared as part of an assignment for the Software Lab
Course (CS251) to learn \LaTeX.

\noindent\fbox{%
    \parbox{.47\textwidth}{%
    Declaration: I have prepared this document us-
    ing \LaTeX\   without any unfair means. Further,
    while the document is prepared by me, I do not
    claim the ownership of the ideas presented in 
    this document.
    }%
}%
\end{abstract}    
\section{Introduction}

Sorting is one of the most fundamental operations
in computer science useful in numerous applica-
tions. Given a sequence of numbers as input, the
output should provide a non-decreasing sequence
of numbers as output. More formally, we define a
sorting problem as follows [1],\\
\textbf{Input}: A sequence of $n$ numbers $\langle a_{1}, a_{2},...,a_{n}\rangle$.\\*
\textbf{Output}: A reordered sequence (of size $n$)
$\langle a_{1}^{'},a_{2}^{'}, ..., a_{n}^{'} \rangle$ of the input sequence such that $a_{1}^{'} \leq a_{2}^{'}\leq...\leq a_{n}^{'}$.\\

Consider the following example. Given an input
sequence $\langle 8, 34, 7, 9, 15, 91, 15\rangle$, a sorting algorithm should return $\langle 7, 8, 9, 15, 15, 34, 91\rangle$ as output.\\

A fundamental problem like sorting has attracted
many researchers who contributed with innovative
algorithms to solve the problem of sorting \textit{effi-
ciently} [3]. Efficiency of an algorithm depends on
primarily on two aspects,

\begin{itemize}
    \item \textbf{Time Complexity}  is a formalism that cap-
        tures running time of an algorithm in terms of
        the input size. Normally, asymptotic behavior
on the input size is used to analyze the time
complexity of algorithms.

\item \textbf{Space Complexity}  is a formalism that cap-
tures amount of memory used by an algorithm
in terms of input size. Like time complexity
analysis, asymptotic analysis is used for space
complexity.

\end{itemize}

In the branch of algorithms and complexity in com-
puter science, space complexity takes a back seat
compared to time complexity. Recently, another
parameter of computing i.e., energy consumption
has become popular. Roy et al. [4] proposed an en-
ergy complexity model for algorithms. In this doc-
ument, we will deal with time complexity of sorting
algorithms. \\

One class of algorithms which are based on \textit{ele-
ment comparison} are commonly known as \textit{compar-
ison based sorting algorithms}. In this document we
will provide a brief overview of \texttt{Quicksort}, a com-
monly used comparison based sorting algorithm [2]. Quicksort is a sorting algorithm based on \textit{divide and conquer} paradigm of algorithm design. Further, we will  derive the lower bound of any comparison based sorting algorithm to be $\Omega(nlog_{2}n$) for an input size of $n$.\\

\section{Quicksort}

Quicksort is designed as a three-step divide-and-
conquer process for sorting an input sequence in
an array [1]. For any given subarray, $A[i..j]$, the
process is as follows,\\*

\textbf{Divide}: The array $A[i..j]$ is partitioned into two
subarrays $A[i..k]$ and $A[k + 1..j]$ such that all ele-
ments in $A[i..k]$ is less than or equal to all elements
in $A[k + 1..j]$. A partitioning procedure is called to
determine $k$ such that at the end of partitioning,
the element at the $k^{th}$ position (i.e., $A[k]$) does not
change its position in the final output array.



%\begin{algorithm}
%\SetAlgoLined
%\KwIn{$A[0..N-1]$: Array of integers}
%\KwOut{$A[0..N-1]$: Sorted array of integers}
%$i \leftarrow$ 1 \;
%\While {$i <  N$}{
%    $j \leftarrow i$ \;
%    Iterate to find the place for this element in the sorted array \;
%   \While {$j > 0$ and $A[j-1] > A[j]$}{
%         swap($A[j]$, $A[j-1]$)\;
%         $j \leftarrow j -1$ \;
%   }
%   $i \leftarrow i + 1$ \;
%   
%    
%}
%
%\label{algo:ins_sort}
%\caption{Sort an array using insertion sort}
%\end{algorithm}

\begin{algorithm}
    \caption{Partition procedure of \texttt{Quicksort} algorithm.}
  \label{algo:qsort1}
  \begin{algorithmic}[1]
      \Procedure{\textsc{PARTITION}}{A,i,j}\newline
      \triangleright $$A$ is an array of $N$ integers, $A[1..N]$\newline
      \triangleright $$i$ and $j$ are the start and end of subarray
      \State $x \leftarrow A[i]$ 
      \State $y \leftarrow i-1$ 
      \State $z \leftarrow j+1$ 
      \While {($true$)}
          \State $z \leftarrow z-1$ 
         \While {$A[z] > x$}
          \State $z \leftarrow z-1$ 
         \EndWhile
         \State $y \leftarrow y+1$ 
         \While {$A[y] < x$}
         \State $y \leftarrow y+1$ 
         \EndWhile 
         \If {$y < z$} 
            \State Swap $A[y] \longleftrightarrow A[z]$
         \Else 
            \State\Return $z$
         \EndIf
      \EndWhile
     \EndProcedure 
  \end{algorithmic}
\end{algorithm}

\textbf{Conquer:} Recursively invoke \texttt{Quicksort} on the two subarrays. This procedure conquers the complexity by applying the same operations in two subarrays.

\textbf{Merge:} Quicksort does not require merge or com-
bine operation as the entire array $A[i..j]$ is sorted
in place.

  In the heart of \texttt{Quicksort}, there is a partition
procedure as shown in Algorithm 1. A pivot ele-
ment $x$ is selected. The first inner while loop (line
$#6$) continues examining elements until it finds an
element that is smaller than or equal to the pivot el-
ement. Similarly, the second inner while loop (line
$#9$) continues examining elements until it finds anelement that is greater than or equal to the pivotelement. If indices $y$ and $z$ have not exchangedtheir side around the pivot, the elements at $A[y]$ and $A[z]$ are exchanged. Otherwise, the procedure returns the index $z$, such that all elements to the left of $z$ are smaller than or equal to $A[z]$ and all
elements to the right of $z$ are greater than or equalto $A[z]$.

  The main recursive procedure for \texttt{Quicksort} is


\begin{algorithm}
    \caption{\texttt{Quicksort} recursion}
  \label{algo:qsort2}
  \begin{algorithmic}[1]
      \Procedure{\scshape{QUICKSORT}}{A,i,j}\newline
      \triangleright $Quicksort procedure called with $A, 1, N$
         \If {$i < j$} 
            \State  $k \leftarrow $PARTITION$(A,i,j)$
            \State QUICKSORT$(A,i,k)$
            \State QUICKSORT$(A,k+1,j)$
         \EndIf
     \EndProcedure 
  \end{algorithmic}
\end{algorithm}

presented in Algorithm 2. Initial invocation is per-
formed by call QUICKSORT$(A, 1, N )$ where $N$ is
the length of array $N$.

\subsection{Time complexity analysis of \texttt{Quicksort}}

The worst case of \texttt{Quicksort} occurs when an ar-
ray of length $N$ , gets partitioned into two subarrays
of size N-1 and 1 in every recursive invocation of
QUICKSORT procedure in Algorithm 2. The par-
titioning procedure presented in Algorithm 1, takes
$\Theta(n)$ time, the recurrence relation for running time
is,

\begin{equation*}
    T(n) = T(n-1) + \Theta(n)
\end{equation*}

\indent
\begin{align*}
    T(n) &= T(n-1) + \Theta(n) \\
        &= \Sigma_{k=1}^{n}\Theta(n) \\
        &= \Theta(\Sigma_{k=1}^{n}k) \\
        &= \Theta(n^{2}) \\
\end{align*}

Therefore, if the partitioning is always maximally
unbalanced, the running time is $\Theta(n^{2})$. Intutively,
if an input sequence is almost sorted, \texttt{Quicksort}
will perform poorly. In the best case, partitioning
divides the array into two equal parts. Thus, the
recurrence for the best case is given by,
    
\indent 
\begin{equation*}
    T(n) = 2T(n/2) + \Theta(n)
\end{equation*}

which evaluates to $\Theta(nlog_{2}n)$. Using a compara-
tively involved analysis, the average running time
of \texttt{Quicksort} can be determined to be $O(n lg n)$.

\section{ Lower bounds on compari-
son sorts}

An interesting question about sorting algorithms
based on comparisons is the following: What is
the lower bound of this class of sorting algo-
rithms? This question is important for algorithm
researchers to further improve the sorting algo-rithms.
A decision tree based analysis leads to the fol-
lowing theorem [1].

\textbf{Theorem 1.} \textit{ Any decision tree that sorts n ele-
ments has height $\Omega(nlog_{2}n)$}.

\textit{Proof.} Consider a decision tree of height $h$ that
sorts $n$ elements. Since there are $n!$ permutations
of $n$ elements, each permutation representing a dis-
tinct sorted order, the tree must have at least $n!$ leaves. Since a binary tree of height $h$ has no more than $2^{h}$ leaves. So,

\indent 
\begin{equation*}
    n! \leq 2^{h}
\end{equation*}

Applying logarithmic ($log_{2}$), the inequality becomes,
\indent 
\begin{equation*}
    h \geq lg(n!)
\end{equation*}

Applying Stirlingâ€™s approximations,
\indent 
\begin{equation*}
    n! >  (n/e)^{n},
\end{equation*}

where $e$ is natural base of logarithms. Further,


\indent
\begin{align*}
    h   &\geq lg(n/e)^{n} \\
        &= nlgn - n lg e \\
        &= \Omega(n lg n) \QEDB \\
\end{align*}

\section{Conclusion}

In this document, we have provided a discussion
on sorting algorithms. We included algorithms for
\texttt{Quicksort} and explained its working. Further, a
proof of lower bounds on sorting is presented in this
document. Most of the content presented here is
created by referring and reproducing contents from
one of the widely followed book on Algorithms by
Cormen et al. [1]. We do not claim originality of
this work. This document is prepared as part of an
assignment for the Software Lab Course (CS251) to
learn \LaTeX.


\begin{thebibliography}{25}
\bibitem{xen}
     Cormen, T. H., Leiserson, C. E., Rivest,
     R. L., and Stein, C. \textit{Introduction to Algorithms,
     Third Edition}, 3rd ed. The MIT Press,
    2009.

\bibitem{vmware}
     Hoare, C. A. R. Algorithm 64: Quicksort.\textit{Communications of ACM 4, 7} (1961), 321â€“.

\bibitem{lxc}
    Martin, W. A. Sorting. \textit{ACM Computing
        Survey 3}, 4 (1971), 147â€“174.

\bibitem{docker}
    Roy, S., Rudra, A., and Verma, A. An en-
        ergy complexity model for algorithms. In Proceedings of the \textit{4th Conference on Innovations  in Theoretical Computer Science} (2013), ITCS$^{'}$13, pp. $283-304$.


\end{thebibliography}
\end{document}
